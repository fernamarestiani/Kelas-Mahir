{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_dasar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS9E3uhiM3Jr"
      },
      "source": [
        "#**Pembuka**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVBUilypM8gp"
      },
      "source": [
        "Assalamu'alaikum warahmatullahi wabarakatuh. Puji syukur kehadirat Allah Subhana Wata'ala atas limpahan Rahmat dan HidayahNya kepada kita semua. Sholawat serta salam senantiasa tercurah limpahkan kepada baginda Muhammad Rasulullah Salallahualaihiwassalam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFgzHc8oM_Nt"
      },
      "source": [
        "Halo para **Pejuang Data**. Selamat berjumpa di pertemuan ketujuh Program Training **Algoritma Machine Learning** Kelas Mahir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r711S4S8NHcY"
      },
      "source": [
        "Pada pertemuan ini kamu akan belajar:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nGmjbHxNMcu"
      },
      "source": [
        "\n",
        "*   Apa itu NLP\n",
        "*   Scrapping Data\n",
        "*   Text Preprocessing\n",
        "\n",
        "      *   Case Folding & Data Cleaning\n",
        "      *   Lemmatisasi\n",
        "      *   Stemming\n",
        "      *   Slang Word\n",
        "      *   Stop Word\n",
        "      *   Unwanted Word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkL398shOqd9"
      },
      "source": [
        "#**Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LhKGJ9Yr-Bf",
        "outputId": "996a7e94-d633-4990-cb5e-6d7572a24cc5"
      },
      "source": [
        "!pip  install google_play_scraper"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google_play_scraper\n",
            "  Downloading google-play-scraper-1.0.2.tar.gz (52 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▏                         | 10 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 30 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 40 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 51 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: google-play-scraper\n",
            "  Building wheel for google-play-scraper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-play-scraper: filename=google_play_scraper-1.0.2-py3-none-any.whl size=24393 sha256=d7bff4d3ada540027b3079eb1679c9c7ebfd4a8baf4db4f3dc01893bfec4ebb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/99/eb/bbb9d24a5c526980647efc10336eaaeffcf07749f581111128\n",
            "Successfully built google-play-scraper\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcKXNbAqM0GD"
      },
      "source": [
        "import sys\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    import warnings\n",
        "    warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI8GpNLWOzdz"
      },
      "source": [
        "#**Natural Language Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBO2blPbO3is"
      },
      "source": [
        "Natural Language Processing (NLP) merupakan salah satu cabang ilmu AI yang berfokus pada pengolahan bahasa natural. Bahasa natural adalah bahasa yang secara umum digunakan oleh manusia dalam berkomunikasi satu sama lain. Bahasa yang diterima oleh komputer butuh untuk diproses dan dipahami terlebih dahulu supaya maksud dari user bisa dipahami dengan baik oleh komputer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SULLsB_7O4YA"
      },
      "source": [
        "Ada berbagai terapan aplikasi dari NLP. Diantaranya adalah Chatbot (aplikasi yang membuat user bisa seolah-olah melakukan komunikasi dengan computer), Stemming atau Lemmatization (pemotongan kata dalam bahasa tertentu menjadi bentuk dasar pengenalan fungsi setiap kata dalam kalimat), Summarization (ringkasan dari bacaan), Translation Tools (menterjemahkan bahasa) dan aplikasi-aplikasi lain yang memungkinkan komputer mampu memahami instruksi bahasa yang diinputkan oleh user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9twuMIZO76S"
      },
      "source": [
        "Pustejovsky dan Stubbs (2012) menjelaskan bahwa ada beberapa area utama penelitian pada field NLP, diantaranya:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaIRQLZ5O-nO"
      },
      "source": [
        "\n",
        "1.   **Question Answering Systems (QAS)**. Kemampuan komputer untuk menjawab pertanyaan yang diberikan oleh user. Daripada memasukkan keyword ke dalam browser pencarian, dengan QAS, user bisa langsung bertanya dalam bahasa natural yang digunakannya, baik itu Inggris, Mandarin, ataupun Indonesia.\n",
        "2.   **Summarization**. Pembuatan ringkasan dari sekumpulan konten dokumen atau email. Dengan menggunakan aplikasi ini, user bisa dibantu untuk mengkonversikan dokumen teks yang besar ke dalam bentuk slide presentasi. Machine Translation. Produk yang dihasilkan adalah aplikasi yang dapat memahami bahasa manusia dan menterjemahkannya ke dalam bahasa lain. Termasuk di dalamnya adalah Google Translate yang apabila dicermati semakin membaik dalam penterjemahan bahasa. Contoh lain lagi adalah BabelFish yang menterjemahkan bahasa pada real time.\n",
        "3.   **Speech Recognition**. Field ini merupakan cabang ilmu NLP yang cukup sulit. Proses pembangunan model untuk digunakan telpon/komputer dalam mengenali bahasa yang diucapkan sudah banyak dikerjakan. Bahasa yang sering digunakan adalah berupa pertanyaan dan perintah.\n",
        "4.   **Document classification**. Sedangkan aplikasi ini adalah merupakan area penelitian NLP Yang paling sukses. Pekerjaan yang dilakukan aplikasi ini adalah menentukan dimana tempat terbaik dokumen yang baru diinputkan ke dalam sistem. Hal ini sangat berguna pada aplikasi spam filtering, news article classification, dan movie review.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm5fMoAjQEI8"
      },
      "source": [
        "#**Scrapping Data Text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFJ2uNVgQIk7"
      },
      "source": [
        "Sebelum melakukan penerapan dan berbagai penelitian. Mengumpulkan data teks sebagai bahan dasar dari bidang ini merupakan hal yang sangat penting. Proses ini biasa disebut dengan scrapping data. Aktivitas scrapping data bisa dilakukan melalui berbagai platfrom. Mulai langsung pada halaman web tertentu, melalui API seperti Twitter, atau melalui tools yang sudah disediakan, bisa free atau berbayar. Untuk mulai belajar NLP, kita akan menggunakan tools. Toolls/Library google_play_scrapper adalah library yang dapat digunakan untuk mengambil review dari google apps. Pertama kita perlu melakukan instalasi sebagai berikut."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_ZoEqzIQLvA"
      },
      "source": [
        "**Instalasi google play scrapper**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IJdEn2OQQvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f7db40-250b-4e27-ff49-1e7e7e092545"
      },
      "source": [
        "!pip install google_play_scraper"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google_play_scraper in /usr/local/lib/python3.7/dist-packages (1.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGAW9OJUQTpX"
      },
      "source": [
        "**Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlOokIMaQZJx"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google_play_scraper import Sort, reviews                  # Librray untuk scrapping data teks\n",
        "import re                                                      # Library untuk teks preprocessing"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4khsOKkjQc7f"
      },
      "source": [
        "**Scrapping Data Review Teks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-613XjxjQl2j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "4ee3fb6e-2fb7-4ae8-aece-dbf55b8217eb"
      },
      "source": [
        "Hasil_Scrapping = pd.read_csv('/content/dataset_tweet_sentiment_pilkada_DKI_2017.csv')\n",
        "Hasil_Scrapping.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Pasangan Calon</th>\n",
              "      <th>Text Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Banyak akun kloning seolah2 pendukung #agussil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>#agussilvy bicara apa kasihan yaa...lap itu ai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Kalau aku sih gak nunggu hasil akhir QC tp lag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Kasian oh kasian dengan peluru 1milyar untuk t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Maaf ya pendukung #AgusSilvy..hayo dukung #Ani...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                         Text Tweet\n",
              "0   1  ...  Banyak akun kloning seolah2 pendukung #agussil...\n",
              "1   2  ...  #agussilvy bicara apa kasihan yaa...lap itu ai...\n",
              "2   3  ...  Kalau aku sih gak nunggu hasil akhir QC tp lag...\n",
              "3   4  ...  Kasian oh kasian dengan peluru 1milyar untuk t...\n",
              "4   5  ...  Maaf ya pendukung #AgusSilvy..hayo dukung #Ani...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g69rpOFYQor1"
      },
      "source": [
        "**Mengambil Series Data Teks Review**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faxbSWzuQskr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9464de23-6307-4713-ee31-88a0be021747"
      },
      "source": [
        "teks=Hasil_Scrapping['Text Tweet']\n",
        "teks"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Banyak akun kloning seolah2 pendukung #agussil...\n",
              "1      #agussilvy bicara apa kasihan yaa...lap itu ai...\n",
              "2      Kalau aku sih gak nunggu hasil akhir QC tp lag...\n",
              "3      Kasian oh kasian dengan peluru 1milyar untuk t...\n",
              "4      Maaf ya pendukung #AgusSilvy..hayo dukung #Ani...\n",
              "                             ...                        \n",
              "895    Kali saja bpk @aniesbaswedan @sandiuno lihat, ...\n",
              "896    Kita harus dapat merangkul semua orang tanpa b...\n",
              "897    Ini jagoanku dibidang digital <Smiling Face Wi...\n",
              "898                 #PesanBijak #OkeOce #GubernurGu3 ...\n",
              "899    Sandiaga: Bangun Rumah DP 0% Lebih Simpel Diba...\n",
              "Name: Text Tweet, Length: 900, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkzgnmF3QxWY"
      },
      "source": [
        "#**Teks Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVb1vy5LQ3CM"
      },
      "source": [
        "Setelah mendapat data teks. Salah satu tantangan dari data teks adalah bentuknya yang sangat beragam. Sebuah kata dapat ditulis dengan berbagai bentuk. Kemudian juga besar sekali kemungkinan adalah kesalahan penulisan. Tanda baca, angka, dan lain-lain. Oleh sebab itu, sebelum diolah lebih lanjut untuk diproses menjadi data numerik, maka diperlukan pemrosesan data teks agar menjadi bentuk yang lebih bersih dan standar. Yang akan sangat mempengaruhi hasil analisis data teks tersebut. Pada sentimen analisis misalnya, langkah ini menjadi sangat penting. Ada beberapa hal yang dilakukan pada tahap Teks Preprocessing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y17qCSdKQ5qJ"
      },
      "source": [
        "\n",
        "**1.   Case Folding & Data Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RaIcNkfRI21"
      },
      "source": [
        "Case folding adalah salah satu bentuk text preprocessing yang paling sederhana dan efektif meskipun sering diabaikan. Tujuan dari case folding untuk mengubah semua huruf dalam dokumen menjadi huruf kecil. Hanya huruf ‘a’ sampai ‘z’ yang diterima. Karakter selain huruf dihilangkan dan dianggap delimiter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu_uQuiGROmK"
      },
      "source": [
        "Ada beberapa cara yang dapat digunakan dalam tahap case folding, diantaranya:\n",
        "\n",
        "\n",
        "\n",
        "*   Menghapus tanda baca\n",
        "*   Menghapus angka\n",
        "*   Mengubah text menjadi lowercase\n",
        "*   Menghapus whitepace (karakter kosong)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HSZAVFURhvA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "612b2f40-75be-48c2-80fb-1dc54fbc5759"
      },
      "source": [
        "# Menghapus tanda baca\n",
        "print(teks[15])\n",
        "teks[15]=re.sub(r'[^\\w]|_',' ', teks[15])\n",
        "teks[15]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "om AA kemana ? lepas #AHY kalah kok dia tutup mulut tidak koar\" mau bongkar SBY\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'om AA kemana   lepas  AHY kalah kok dia tutup mulut tidak koar  mau bongkar SBY'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xJYFAXYRkmh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9e6c289a-73cc-49cb-bc07-05ffeb96d36d"
      },
      "source": [
        "# Menghapus angka \n",
        "print(teks[899])\n",
        "teks[899] = re.sub(\"\\S*\\d\\S*\", \"\", teks[899]).strip()\n",
        "teks[899] = re.sub(r\"\\b\\d+\\b\", \" \", teks[899])\n",
        "teks[899]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sandiaga: Bangun Rumah DP 0% Lebih Simpel Dibanding Tol Cipali #AniesSandiJawaraJakarta #GubernurGu3 #OkeOce #DP0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sandiaga: Bangun Rumah DP  Lebih Simpel Dibanding Tol Cipali #AniesSandiJawaraJakarta  #OkeOce'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m8jegpjRnab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "ea67ba41-35bc-4d94-82c9-6fa778776065"
      },
      "source": [
        "#Mengubah text menjadi lowercase\n",
        "print(teks[11])\n",
        "\n",
        "teks[11]=teks[11].lower()\n",
        "teks[11]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batal nyoblos, baru tau ternyata ga ada no.1 di kertas suara. #AHY #kangen #mosing\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'batal nyoblos, baru tau ternyata ga ada no.1 di kertas suara. #ahy #kangen #mosing\\t'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILFXFSzKRp0g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "91e80c33-b380-4789-ceea-27f59ec2e553"
      },
      "source": [
        "# Menghapus white space\n",
        "print(teks[11])\n",
        "\n",
        "teks[11]=re.sub('[\\s]+', ' ', teks[11])\n",
        "teks[11]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batal nyoblos, baru tau ternyata ga ada no.1 di kertas suara. #ahy #kangen #mosing\t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'batal nyoblos, baru tau ternyata ga ada no.1 di kertas suara. #ahy #kangen #mosing '"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz8fmHQLRt2K"
      },
      "source": [
        "Membuat Fungsi untuk Melakukan Case Folding\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJrdI8XfRx-4"
      },
      "source": [
        "import re, string, unicodedata \n",
        "def Case_Folding(text):\n",
        "    # Hapus non-ascii\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    \n",
        "    # Menghapus Tanda Baca\n",
        "    text = re.sub(r'[^\\w]|_',' ', text)\n",
        "    \n",
        "    # Menghapus Angka\n",
        "    text = re.sub(\"\\S*\\d\\S*\", \"\", text).strip()\n",
        "    text = re.sub(r\"\\b\\d+\\b\", \" \", text)\n",
        "    \n",
        "    # Mengubah text menjadi lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Menghapus white space\n",
        "    text = re.sub('[\\s]+', ' ', text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGQJ18OnR00q"
      },
      "source": [
        "#**Lemmatization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4_WJ9anR58-"
      },
      "source": [
        "Proses pengurangan berbagai bentuk kata yang berubah menjadi satu bentuk untuk memudahkan analisis. e.g. kata dari “swim”, “swimming”, “swims”, “swam”, adalah semua bentuk dari “swim”. Nah jadi lemma dari semua kata-kata tersebut adalah “swim”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od-cZ62VR-G9"
      },
      "source": [
        "Untuk data teks berbahasa Indonesia, kita akan menggunakan library nlp-id. Pertama kita harus menginstallnya terlebih dahulu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ45DIg2SAsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c70294-4070-4781-a3d3-bbcdf19b21cd"
      },
      "source": [
        "!pip install nlp-id"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nlp-id\n",
            "  Downloading nlp_id-0.1.12.0.tar.gz (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 8.7 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22\n",
            "  Downloading scikit_learn-0.22-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 3.0 MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 50.3 MB/s \n",
            "\u001b[?25hCollecting wget==3.2\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->nlp-id) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22->nlp-id) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22->nlp-id) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22->nlp-id) (1.19.5)\n",
            "Building wheels for collected packages: nlp-id, nltk, wget\n",
            "  Building wheel for nlp-id (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nlp-id: filename=nlp_id-0.1.12.0-py3-none-any.whl size=8074105 sha256=5d621b5d0dc18d3ce5c7fab8bc3356cff29158a6e233f62c5ad404ab5a802d80\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/50/48/da59531125bd94f48dfe66140f41d8fd8a4f04062050375013\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449922 sha256=0be573fdf360d45be5ae233e81fefdf8765da6c9cad3ed7e7c7cbb4c6ef9a7df\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=1547ac7472b1247ab2bf5cc237a554b46e0514d69c07594162bd2001c0dffc39\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built nlp-id nltk wget\n",
            "Installing collected packages: wget, scikit-learn, nltk, nlp-id\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nlp-id-0.1.12.0 nltk-3.4.5 scikit-learn-0.22 wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1NwmUexSDRF"
      },
      "source": [
        "Kemudian kita akan menggunakan fungsi Lemmatizer() untuk melakukan lemmatisasi data teks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk_eOtrmSHMf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "332aadbb-a6c0-4c89-88e0-bfffb4334cb6"
      },
      "source": [
        "from nlp_id.lemmatizer import Lemmatizer \n",
        "lemmatizer = Lemmatizer() \n",
        "print(teks[11])\n",
        "teks[11]=lemmatizer.lemmatize(teks[11]) \n",
        "teks[11]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batal nyoblos, baru tau ternyata ga ada no.1 di kertas suara. #ahy #kangen #mosing \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'batal nyoblos baru tau nyata ga ada no 1 di kertas suara ahy kangen mosing'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnmUN7qHSKSD"
      },
      "source": [
        "#**Stemming**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsCrjPw8SQa1"
      },
      "source": [
        "Stemming merupakan suatu proses untuk menemukan kata dasar dari sebuah kata. Dengan menghilangkan semua imbuhan (affixes) baik yang terdiri dari awalan (prefixes), sisipan (infixes), akhiran (suffixes) dan confixes (kombinasi dari awalan dan akhiran) pada kata turunan. Stemming digunakan untuk mengganti bentuk dari suatu kata menjadi kata dasar dari kata tersebut yang sesuai dengan struktur morfologi Bahasa Indonesia yang baik dan benar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbpm73QuSXFZ"
      },
      "source": [
        "Untuk data teks berbahasa Indonesia, kita akan menggunakan library PySastrawi. Pertama kita harus menginstallnya terlebih dahulu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ua1G6NVSJ99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d253daaa-8202-4e47-a4f5-f117c3d1226c"
      },
      "source": [
        "!pip install PySastrawi"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PySastrawi\n",
            "  Downloading PySastrawi-1.2.0-py2.py3-none-any.whl (210 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40 kB 19.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 51 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 61 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 81 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 102 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 112 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 122 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 133 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 143 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 153 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 163 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 174 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 194 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 204 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 210 kB 8.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: PySastrawi\n",
            "Successfully installed PySastrawi-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9jHz7_pSnjb"
      },
      "source": [
        "Kemudian kita akan menggunakan fungsi StemmerFactory() untuk melakukan stemming."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQp9oJppSqMH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "ba003f24-8897-4868-d927-ef7f9928991b"
      },
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "# Membuat stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "print(teks[12])\n",
        "\n",
        "teks[12] = stemmer.stem(teks[12])\n",
        "teks[12]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sudah boleh Ngakak? survey mu jauh panggang dari api ! #Ahy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sudah boleh ngakak survey mu jauh panggang dari api ahy'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBHTZsJWSum1"
      },
      "source": [
        "#**Slang Words**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OWMEobiSzK8"
      },
      "source": [
        "Slang adalah kata-kata yang tidak baku secara bahasa namun sering dipakai oleh pengguna bahasa. Kita perlu melakukan standarisasi untuk slang."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_WDC9AzS3oZ"
      },
      "source": [
        "slang_dictionary = pd.read_csv('https://raw.githubusercontent.com/nikovs/data-science-portfolio/master/topic%20modelling/colloquial-indonesian-lexicon.csv')\n",
        "slang_dict = pd.Series(slang_dictionary['formal'].values,index=slang_dictionary['slang']).to_dict()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duaQpygNS6n0"
      },
      "source": [
        "def Slangwords(text):\n",
        "    for word in text.split():\n",
        "        if word in slang_dict.keys():\n",
        "            text = text.replace(word, slang_dict[word])\n",
        "    return text"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-eQ5rvyS-QQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "47152ae2-3ee3-4f87-c9e8-c743eba117da"
      },
      "source": [
        "print(teks[0])\n",
        "\n",
        "teks[0]=Slangwords(teks[0]) \n",
        "teks[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Banyak akun kloning seolah2 pendukung #agussilvy mulai menyerang paslon #aniessandi dengan opini dan argumen pmbenaran..jangan terkecoh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Banyak akun kloning seolah2 pendukung #agussilvy mulai menyerang paslon #aniessandi dengan opini dan argumen pmbenaran..jangan terkecoh'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY-9pbFdTAxo"
      },
      "source": [
        "#**Stopword**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FDdrtR3TFVd"
      },
      "source": [
        "Stop words adalah kata umum (common words) yang biasanya muncul dalam jumlah besar dan dianggap tidak memiliki makna. Stop words umumnya dimanfaatkan dalam task information retrieval, termasuk oleh Google (penjelasannya di sini). Contoh stop words untuk bahasa Inggris diantaranya “of”, “the”. Sedangkan untuk bahasa Indonesia diantaranya “yang”, “di”, “ke”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-kebuFDTHs9"
      },
      "source": [
        "from nlp_id.stopword import StopWord \n",
        "stopword = StopWord()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSck1mbTTKP9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "1cbb794c-0a0b-445a-ea44-98216eec7856"
      },
      "source": [
        "from nlp_id.stopword import StopWord \n",
        "print(teks[11])\n",
        "\n",
        "teks[11]=stopword.remove_stopword(teks[11])\n",
        "teks[11]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batal nyoblos baru tau nyata ga ada no 1 di kertas suara ahy kangen mosing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'batal nyoblos tau nyata ga no 1 kertas ahy kangen mosing'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEjuPPXxT-_8"
      },
      "source": [
        "#**Unwanted Words**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56ks6IMVUDi7"
      },
      "source": [
        "Unwanted words adalah kata-kata yang berada di luar beberapa hal di atas namun perlu untuk kita hapus. Kita bisa mendefinisikan sendiri kata-kata atau karakter yang ingin kita hilangkan dari data teks yang kita peroleh.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi6kyfb3UO7a"
      },
      "source": [
        "unwanted_words = ['sy', 'karna', 'gue', 'pun', 'nya', 'yg', 'gw', 'ke', 'gak', 'ga', 'buat', 'selama', 'akan', 'gua', 'gw', \n",
        "                 'gue', 'dampak', 'tau', 'banget', 'mohon', 'dii', 'kalo', 'dll', 'kadang', 'ya', 'coba', 'langsung',\n",
        "                 'cuman', 'cuma', 'biar', 'an', 'kayak', 'dar', 'bikin', 'ssaja', 'sih', 'si', 'situ', 'e', 'utk', 'pake',\n",
        "                 'diin', 'serba', 'ampun', 'untuj', 'deh', 'jd', 'ku', 'total', 'lg', 'arti', 'terimakasih','and', 'udah',\n",
        "                 'kali', 'dasar', 'tiada', 'indonesia', 'pas', 'tidiak', 'the', 'http', 'co', 'com', 'di', 'https', 'kak',\n",
        "                 'dr', 'aja', 'klo', 'tp', 'gitu', 'udh', 'min', 'halo', 'tidak', 'bisa', 'sudah', 'yg', 'apa', 'malah',\n",
        "                 'masih', 'mau', 'kok', 'belum', 'buat', 'atau', 'sama', 'gak', 'ga', 'udah', 'banyak', 'selalu', 'masuk',\n",
        "                 'atau', 'belum', 'ini', 'tp', 'ke', 'ya', 'itu', 'aja', 'saja', 'juga', 'aplikasi', 'my pertamina',\n",
        "                 'mypertamina', 'maaf', 'gk', 'tdk', 'trus', 'jg', 'nih', 'sdh', 'mulu', 'padahal', 'kenapa', 'gimana',\n",
        "                 'gmn', 'sih', 'bs', 'suruh', 'tolong', 'dah', 'bagus', 'my', 'pertamina', 'jadi', 'kalau', 'engenggakk',\n",
        "                 'engenggak', 'pakai', 'bilang', 'mending', 'hasil', 'orang', 'muncul', 'ssudah', 'kasih', 'mala', 'malah']"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ox9EpDvUR1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b912ff-7286-4d9a-e457-ce24a77c06bd"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "def RemoveUnwantedwords(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_sentence = [word for word in word_tokens if not word in unwanted_words]\n",
        "    return ' '.join(filtered_sentence)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHKGxTeOUVSl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "c78d3de2-1689-45a1-e723-97c34300d4ad"
      },
      "source": [
        "print(teks[0])\n",
        "\n",
        "teks[0]=RemoveUnwantedwords(teks[0])\n",
        "teks[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Banyak akun kloning seolah2 pendukung #agussilvy mulai menyerang paslon #aniessandi dengan opini dan argumen pmbenaran..jangan terkecoh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Banyak akun kloning seolah2 pendukung # agussilvy mulai menyerang paslon # aniessandi dengan opini dan argumen pmbenaran..jangan terkecoh'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA1NNrF1UY6P"
      },
      "source": [
        "#**Menerapkan Semua Langkah**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp5U-1eLUd6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8b18b91-dbee-41c8-a06d-c937cd6f817a"
      },
      "source": [
        "Hasil_Scrapping['content_processed'] = ''\n",
        "\n",
        "for i, row in Hasil_Scrapping.iterrows():\n",
        "    content = Hasil_Scrapping['Text Tweet'][i]\n",
        "    result = Case_Folding(content)\n",
        "    result = lemmatizer.lemmatize(result)\n",
        "    result = stemmer.stem(result)\n",
        "    result = Slangwords(result)\n",
        "    result = stopword.remove_stopword(result)\n",
        "    result = RemoveUnwantedwords(result)\n",
        "    Hasil_Scrapping['content_processed'][i] = result"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx_-vh8eUg4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "c7e5cb39-d69e-49c9-e1da-0953ea20c02c"
      },
      "source": [
        "Hasil_Scrapping[['Text Tweet', 'content_processed']]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text Tweet</th>\n",
              "      <th>content_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Banyak akun kloning seolah2 pendukung # agussi...</td>\n",
              "      <td>akun kloning dukung agussilvy serang paslon an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#agussilvy bicara apa kasihan yaa...lap itu ai...</td>\n",
              "      <td>agussilvy bicara kasihan lap air mata wkwkwkwk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kalau aku sih gak nunggu hasil akhir QC tp lag...</td>\n",
              "      <td>enggak memenunggu qc memenunggu motif cuit sby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kasian oh kasian dengan peluru 1milyar untuk t...</td>\n",
              "      <td>kasihh oh kasihh peluru rw agussilvy mempan me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Maaf ya pendukung #AgusSilvy..hayo dukung #Ani...</td>\n",
              "      <td>dukung agussilvy hayo dukung aniessandi putar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>Kali saja bpk @aniesbaswedan @sandiuno lihat, ...</td>\n",
              "      <td>bpk aniesbaswedan sandiuno lihat rspun selfie ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>Kita harus dapat merangkul semua orang tanpa b...</td>\n",
              "      <td>rangkul batas usia kelamin okeoce ok hand sala...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>Ini jagoanku dibidang digital &lt;Smiling Face Wi...</td>\n",
              "      <td>jago bidang digital smiling face with sunglass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>#PesanBijak #OkeOce #GubernurGu3 ...</td>\n",
              "      <td>pesanbijak okeoce</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>Sandiaga: Bangun Rumah DP  Lebih Simpel Diband...</td>\n",
              "      <td>sandiaga bangun rumah dp simpel banding tol ci...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>900 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Text Tweet                                  content_processed\n",
              "0    Banyak akun kloning seolah2 pendukung # agussi...  akun kloning dukung agussilvy serang paslon an...\n",
              "1    #agussilvy bicara apa kasihan yaa...lap itu ai...     agussilvy bicara kasihan lap air mata wkwkwkwk\n",
              "2    Kalau aku sih gak nunggu hasil akhir QC tp lag...  enggak memenunggu qc memenunggu motif cuit sby...\n",
              "3    Kasian oh kasian dengan peluru 1milyar untuk t...  kasihh oh kasihh peluru rw agussilvy mempan me...\n",
              "4    Maaf ya pendukung #AgusSilvy..hayo dukung #Ani...  dukung agussilvy hayo dukung aniessandi putar ...\n",
              "..                                                 ...                                                ...\n",
              "895  Kali saja bpk @aniesbaswedan @sandiuno lihat, ...  bpk aniesbaswedan sandiuno lihat rspun selfie ...\n",
              "896  Kita harus dapat merangkul semua orang tanpa b...  rangkul batas usia kelamin okeoce ok hand sala...\n",
              "897  Ini jagoanku dibidang digital <Smiling Face Wi...  jago bidang digital smiling face with sunglass...\n",
              "898               #PesanBijak #OkeOce #GubernurGu3 ...                                  pesanbijak okeoce\n",
              "899  Sandiaga: Bangun Rumah DP  Lebih Simpel Diband...  sandiaga bangun rumah dp simpel banding tol ci...\n",
              "\n",
              "[900 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-sNhQi1UjXs"
      },
      "source": [
        "Hasil_Scrapping.to_csv('Pilkada_DKI.csv',index=False)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "OjibyfGotZfX",
        "outputId": "f5d8f01c-b50a-4ae9-c9b8-eb81bf858e3f"
      },
      "source": [
        "pd.read_csv('Pilkada_DKI.csv')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Pasangan Calon</th>\n",
              "      <th>Text Tweet</th>\n",
              "      <th>content_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Banyak akun kloning seolah2 pendukung # agussi...</td>\n",
              "      <td>akun kloning dukung agussilvy serang paslon an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>#agussilvy bicara apa kasihan yaa...lap itu ai...</td>\n",
              "      <td>agussilvy bicara kasihan lap air mata wkwkwkwk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Kalau aku sih gak nunggu hasil akhir QC tp lag...</td>\n",
              "      <td>enggak memenunggu qc memenunggu motif cuit sby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Kasian oh kasian dengan peluru 1milyar untuk t...</td>\n",
              "      <td>kasihh oh kasihh peluru rw agussilvy mempan me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Maaf ya pendukung #AgusSilvy..hayo dukung #Ani...</td>\n",
              "      <td>dukung agussilvy hayo dukung aniessandi putar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>896</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Kali saja bpk @aniesbaswedan @sandiuno lihat, ...</td>\n",
              "      <td>bpk aniesbaswedan sandiuno lihat rspun selfie ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>897</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Kita harus dapat merangkul semua orang tanpa b...</td>\n",
              "      <td>rangkul batas usia kelamin okeoce ok hand sala...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>898</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Ini jagoanku dibidang digital &lt;Smiling Face Wi...</td>\n",
              "      <td>jago bidang digital smiling face with sunglass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>899</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>#PesanBijak #OkeOce #GubernurGu3 ...</td>\n",
              "      <td>pesanbijak okeoce</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>900</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Sandiaga: Bangun Rumah DP  Lebih Simpel Diband...</td>\n",
              "      <td>sandiaga bangun rumah dp simpel banding tol ci...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>900 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Id  ...                                  content_processed\n",
              "0      1  ...  akun kloning dukung agussilvy serang paslon an...\n",
              "1      2  ...     agussilvy bicara kasihan lap air mata wkwkwkwk\n",
              "2      3  ...  enggak memenunggu qc memenunggu motif cuit sby...\n",
              "3      4  ...  kasihh oh kasihh peluru rw agussilvy mempan me...\n",
              "4      5  ...  dukung agussilvy hayo dukung aniessandi putar ...\n",
              "..   ...  ...                                                ...\n",
              "895  896  ...  bpk aniesbaswedan sandiuno lihat rspun selfie ...\n",
              "896  897  ...  rangkul batas usia kelamin okeoce ok hand sala...\n",
              "897  898  ...  jago bidang digital smiling face with sunglass...\n",
              "898  899  ...                                  pesanbijak okeoce\n",
              "899  900  ...  sandiaga bangun rumah dp simpel banding tol ci...\n",
              "\n",
              "[900 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iqhstVOUlv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca281e5e-119b-44e8-a93b-08df2809b485"
      },
      "source": [
        "Hasil_Scrapping.info()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 900 entries, 0 to 899\n",
            "Data columns (total 5 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   Id                 900 non-null    int64 \n",
            " 1   Sentiment          900 non-null    object\n",
            " 2   Pasangan Calon     900 non-null    object\n",
            " 3   Text Tweet         900 non-null    object\n",
            " 4   content_processed  900 non-null    object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 35.3+ KB\n"
          ]
        }
      ]
    }
  ]
}